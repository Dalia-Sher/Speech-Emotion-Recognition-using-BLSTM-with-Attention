# Speech-Emotion-Recognition-using-BLSTM-with-Attention
We present a study of a neural network based method for speech emotion recognition, using audio-only features. In the studied scheme, the acoustic features are extracted from the audio utterances and fed to a neural network that consists of CNN layers, BLSTM combined with an attention mechanism layer, and a fully-connected layer. To illustrate and analyze the classification capabilities of the network we used the t-SNE method. We evaluated our model using RAVDESS and IEMOCAP databases.

data were downloded from here: 
IEMOCAP: 
https://www.kaggle.com/datasets/jamaliasultanajisha/iemocap-full 
RAVDESS: 
https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio 
